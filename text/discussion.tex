\section{Diskussion}\label{discussion}
Im Verlauf der Implementierung traten immer wieder Schwierigkeiten auf, die vor allem auf die undetaillierte Beschreibung der CRBM in den entsprechenden Artikeln zurückzuführen sind. Viele der Eigenschaften einer CRBM konnten auf mehrere Weisen interpretiert werden, weshalb das Ausprobieren verschiedener Einstellungen und Verfahren notwendig war.

Die übliche Normalisierung eines Filterkernels ist für das Training der Filterkernel nicht geeignet, da sich alle Kernel zu Boxfiltern entwickelten. Dieser Umstand wurde in keiner der Quellen beschrieben.

In der Master-Thesis von Norouzi \cite{NorouziMaster} wurden ein Trainingsalgorithmus als Pseudo-Code angegeben, an dem sich diese Implementierung orientiert. In diesem Code wurde die Verwendung eines Bias vorgeschlagen, der allerdings nicht innerhalb des Trainings verändert wird. Diverse feste Biaswerte konnten gewählt werden, die aber keinerlei Zuwachs an Klassifizierungsgenauigkeit brachten, weshalb in der aktuellen Implementierung kein Bias vorhanden ist. Vielleicht können in Zukunft Verfahren für dynamische Bias-Werte implementiert werden, die sich an den Datenbestand anpassen.
Auch wird in der Thesis die Filterung mittels eines drei-dimensionalen Kernels beschrieben, welcher bei der Kaskadierung zum Einsatz kommt,  um zu verhindern, dass  sich die Anzahl der Feature-Maps vervielfacht. Dieser drei-dimensionale Kernel wirkt somit dieser Vervielfachung in einer Kaskade entgegen. Es wird jedoch nicht erwähnt, ob oder wie dieser entsprechende Kernel gelernt wird.

Da das Clustering nicht linear erfolgt, ist die Abstandsmessung des Mittelpuktes eines Clusters nicht ausreichend, um den Effekt der CRBM genauer analysieren zu können. Erst durch Methoden, wie den Support Vector Machines kann der Fehler der Klassifizierung minimiert werden.

Abschließend ist anzumerken, dass die rudimentäre Implementierung in Java das Grundkonzept der CRBM umsetzt, aber noch keine vollständig zufriedenstellenden Ergebnisse liefert. Dazu müssen in Zukunft weitere Einstellungsmöglichkeiten getestet und ein besseres Clustering-Verfahren für multidimensionale Daten umgesetzt werden.